{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SincNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL1PRu4M-xdf"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To585oC5HipE"
      },
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import os\n",
        "import glob\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekWjVCeCu75R",
        "outputId": "fbfde8cb-cd9f-4313-dff4-a4dea219dc5d"
      },
      "source": [
        "  !pip install python_speech_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python_speech_features in /usr/local/lib/python3.6/dist-packages (0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPJtG4Znwuqk"
      },
      "source": [
        "import wave\n",
        "import python_speech_features as ps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWsMSGkcHptW"
      },
      "source": [
        "import itertools\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statistics \n",
        "import scipy.stats\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG9ran4LV-t4"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, layers, Model, utils, initializers, losses, optimizers, Sequential, callbacks, backend\n",
        "from keras.utils import conv_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTZY5ppsHn6Q"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import recall_score as recall\n",
        "from sklearn.metrics import confusion_matrix as confusion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVhLXfk9iT3m",
        "outputId": "99377459-809f-4ebf-bd27-26febc149ddb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3PlVPgsiVzA",
        "outputId": "82effef8-2783-4708-8405-40a5e8338440"
      },
      "source": [
        "%cd '/content/drive/My Drive/BTP - Dev Priya and Kushagra/Speech Emotion Recognition/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/BTP - Dev Priya and Kushagra/Speech Emotion Recognition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYsuePNzGdki"
      },
      "source": [
        "dataset_dir = 'Datasets/SincNet'\n",
        "ser_output_dir = 'Final Outputs/SincNet'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHo4IJmmiZap"
      },
      "source": [
        "speaker_list = ['1F', '1M', '2F', '2M', '3F', '3M', '4F', '4M', '5F', '5M']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrG466Ndblzt"
      },
      "source": [
        "# Preprocessing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C4LwwdPvzvI"
      },
      "source": [
        "## For Sincnet Raw features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chiOMSq4Nei6"
      },
      "source": [
        "class PreProcess:\n",
        "\n",
        "    def __init__(self, root_dir, wav_files=None):\n",
        "        self.eps = 1e-5\n",
        "        self.sampling_rate = 16000\n",
        "        self.segment_length = 4000\n",
        "        self.sample_length = {'hap': 6000, 'ang': 8000, 'neu': 20000, 'sad': 16000}\n",
        "        self.root_dir = root_dir\n",
        "        self.valid_session = None\n",
        "        self.valid_gender = None\n",
        "        self.test_session = None\n",
        "        self.test_gender = None\n",
        "        self.output_file_name = None\n",
        "        self.num_per_emo = None\n",
        "\n",
        "        self.train_num = 0\n",
        "        self.test_utterance_num = 0\n",
        "        self.valid_utterance_num = 0\n",
        "        self.test_segment_num = 0\n",
        "        self.valid_segment_num = 0\n",
        "\n",
        "        self.train_emt = {'hap': 0, 'ang': 0, 'neu': 0, 'sad': 0}\n",
        "        self.test_emt = {'hap': 0, 'ang': 0, 'neu': 0, 'sad': 0}\n",
        "        self.valid_emt = {'hap': 0, 'ang': 0, 'neu': 0, 'sad': 0}\n",
        "\n",
        "        self.train_data = None\n",
        "        self.test_data = None\n",
        "        self.valid_data = None\n",
        "\n",
        "        self.train_label = None\n",
        "        self.test_label_utterance = None\n",
        "        self.test_label_segment = None\n",
        "        self.valid_label_utterance = None\n",
        "        self.valid_label_segment = None\n",
        "\n",
        "        self.test_segments_per_utterance = None\n",
        "        self.valid_segments_per_utterance = None\n",
        "\n",
        "        self.mean, self.std = 0, 0\n",
        "\n",
        "        self.wav_files = wav_files\n",
        "        self.read_IEMOCAP()\n",
        "    \n",
        "    def read_wav_file(self, wav_filename):\n",
        "        \"\"\"Read the audio files in wav format and store the wave data\"\"\"\n",
        "        y, sr = librosa.load(wav_filename, sr=self.sampling_rate)\n",
        "        return y\n",
        "\n",
        "    def get_audio_length(self, wav_filename):\n",
        "        \"\"\"Read the audio files in wav format and store the wave data\"\"\"\n",
        "        y, sr = librosa.load(wav_filename, sr=self.sampling_rate)\n",
        "        return y.shape[0]\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_label(emotion):\n",
        "        if emotion == 'ang':\n",
        "            return 0\n",
        "        elif emotion == 'sad':\n",
        "            return 1\n",
        "        elif emotion == 'hap':\n",
        "            return 2\n",
        "        elif emotion == 'neu':\n",
        "            return 3\n",
        "        return 4\n",
        "\n",
        "    @staticmethod\n",
        "    def parse_emo_file(emo_file_name):\n",
        "        emo_map = {}\n",
        "        with open(emo_file_name, 'r') as emo_file:\n",
        "            while True:\n",
        "                line = emo_file.readline()\n",
        "                if not line:\n",
        "                    break\n",
        "                if line[0] != '[':\n",
        "                    continue\n",
        "                t = line.split()\n",
        "                emo_map[t[3]] = t[4]\n",
        "        return emo_map\n",
        "\n",
        "    def read_IEMOCAP(self):\n",
        "        \"\"\"Read the data files and generate a dict with generated features\"\"\"\n",
        "        if self.wav_files is not None:\n",
        "            return\n",
        "        self.wav_files = {}\n",
        "        for session in sorted(os.listdir(self.root_dir)):\n",
        "            if session[0] != 'S':\n",
        "                continue\n",
        "            wav_dir = os.path.join(self.root_dir, session, 'sentences', 'wav')\n",
        "            emo_labels_dir = os.path.join(self.root_dir, session, 'dialog', 'EmoEvaluation')\n",
        "            for impro in sorted(os.listdir(wav_dir)):\n",
        "                if impro[7] != 'i':\n",
        "                    continue\n",
        "                emo_file_name = os.path.join(emo_labels_dir, impro + '.txt')\n",
        "                emo_map = self.parse_emo_file(emo_file_name)\n",
        "                file_dir = os.path.join(wav_dir, impro, '*.wav')\n",
        "                files = glob.glob(file_dir)\n",
        "                print(file_dir)\n",
        "                for filename in sorted(files):\n",
        "                    wav_name = os.path.basename(filename)\n",
        "                    wav_name = os.path.splitext(wav_name)[0]\n",
        "                    emotion = emo_map[wav_name]\n",
        "                    if emotion not in ['hap', 'ang', 'neu', 'sad']:\n",
        "                        continue\n",
        "                    len = self.get_audio_length(filename)\n",
        "                    self.wav_files[wav_name] = {\n",
        "                        'emotion': emotion,\n",
        "                        'len': len,\n",
        "                        'path': filename\n",
        "                    }\n",
        "        # print(self.wav_files)\n",
        "\n",
        "    def update_count(self, emotion, set_type):\n",
        "        if set_type == 'train':\n",
        "            self.train_emt[emotion] += 1\n",
        "            self.train_num += 1\n",
        "        elif set_type == 'test':\n",
        "            self.test_emt[emotion] += 1\n",
        "            self.test_segment_num += 1\n",
        "        else:\n",
        "            self.valid_emt[emotion] += 1\n",
        "            self.valid_segment_num += 1\n",
        "\n",
        "    def initialize(self):\n",
        "        self.train_data = np.empty((self.train_num, self.segment_length), dtype=np.float32)\n",
        "        self.test_data = np.empty((self.test_segment_num, self.segment_length), dtype=np.float32)\n",
        "        self.valid_data = np.empty((self.valid_segment_num, self.segment_length), dtype=np.float32)\n",
        "\n",
        "        self.train_label = np.empty((self.train_num, 1), dtype=np.int8)\n",
        "        self.test_label_segment = np.empty((self.test_segment_num, 1), dtype=np.int8)\n",
        "        self.valid_label_segment = np.empty((self.valid_segment_num, 1), dtype=np.int8)\n",
        "        self.test_label_utterance = np.empty((self.test_utterance_num, 1), dtype=np.int8)\n",
        "        self.valid_label_utterance = np.empty((self.valid_utterance_num, 1), dtype=np.int8)\n",
        "\n",
        "        self.test_segments_per_utterance = np.zeros((self.test_utterance_num, 1), dtype=np.int8)\n",
        "        self.valid_segments_per_utterance = np.zeros((self.valid_utterance_num, 1), dtype=np.int8)\n",
        "\n",
        "        self.train_num = 0\n",
        "        self.test_segment_num = 0\n",
        "        self.valid_segment_num = 0\n",
        "        self.test_utterance_num = 0\n",
        "        self.valid_utterance_num = 0\n",
        "\n",
        "    def count_data(self):\n",
        "        self.train_num = 0\n",
        "        self.test_utterance_num = 0\n",
        "        self.valid_utterance_num = 0\n",
        "        self.test_segment_num = 0\n",
        "        self.valid_segment_num = 0\n",
        "\n",
        "        self.train_emt = {'hap': 0, 'ang': 0, 'neu': 0, 'sad': 0}\n",
        "        self.test_emt = {'hap': 0, 'ang': 0, 'neu': 0, 'sad': 0}\n",
        "        self.valid_emt = {'hap': 0, 'ang': 0, 'neu': 0, 'sad': 0}\n",
        "\n",
        "        for wav_name in sorted(self.wav_files.keys()):\n",
        "            len = self.wav_files[wav_name]['len']\n",
        "            emotion = self.wav_files[wav_name]['emotion']\n",
        "            set_type = self.find_set(wav_name)  # train/test/validation\n",
        "\n",
        "            if set_type == 'train':\n",
        "                if len <= self.sample_length[emotion]:\n",
        "                    continue\n",
        "                samples, rem = divmod(len, self.sample_length[emotion])\n",
        "                start_times = [i * self.sample_length[emotion] for i in range(samples)]\n",
        "                if rem >= self.segment_length:\n",
        "                    start_times += [samples * self.sample_length[emotion]]\n",
        "                end_times = [i + self.sample_length[emotion] for i in start_times]\n",
        "            else:\n",
        "                segments, rem = divmod(len, self.segment_length)\n",
        "                start_times = [i * self.segment_length for i in range(segments)]\n",
        "                if rem >= self.segment_length // 2:\n",
        "                    start_times += [samples * self.segment_length[emotion]]\n",
        "                end_times = [i + self.segment_length for i in start_times]\n",
        "            \n",
        "            for begin, end in zip(start_times, end_times):\n",
        "                self.update_count(emotion, set_type)\n",
        "\n",
        "            if set_type == 'validation':\n",
        "                self.valid_utterance_num += 1\n",
        "            if set_type == 'test':\n",
        "                self.test_utterance_num += 1\n",
        "\n",
        "        print(self.train_emt)\n",
        "        print(self.test_emt)\n",
        "        print(self.valid_emt)\n",
        "        self.num_per_emo = min(self.train_emt['hap'], self.train_emt['sad'], \n",
        "                               self.train_emt['ang'], self.train_emt['neu'])\n",
        "        \n",
        "        print(self.num_per_emo)\n",
        "\n",
        "    def add_to_set(self, part, emotion, set_type):\n",
        "        # TODO extend it for test validation\n",
        "        if set_type == 'train':\n",
        "            self.train_data[self.train_num, :] = part.copy()\n",
        "            self.train_label[self.train_num] = emotion\n",
        "            self.train_num += 1\n",
        "        elif set_type == 'test':\n",
        "            self.test_data[self.test_segment_num, :] = part.copy()\n",
        "            self.test_label_segment[self.test_segment_num] = emotion\n",
        "            self.test_segments_per_utterance[self.test_utterance_num] += 1\n",
        "            self.test_segment_num += 1\n",
        "        else:\n",
        "            self.valid_data[self.valid_segment_num, :] = part.copy()\n",
        "            self.valid_label_segment[self.valid_segment_num] = emotion\n",
        "            self.valid_segments_per_utterance[self.valid_utterance_num] += 1\n",
        "            self.valid_segment_num += 1\n",
        "        # print('\\t'.join((str(train_num), wavname, '0', 'self.frame_num', emotion)))\n",
        "\n",
        "    def find_set(self, wav_name):\n",
        "        \"\"\"returns whether the wav_name should be part of train/test/validation set\"\"\"\n",
        "        if wav_name[4] == self.valid_session and wav_name[-4] == self.valid_gender:\n",
        "            return 'validation'\n",
        "        if wav_name[4] == self.test_session and wav_name[-4] == self.test_gender:\n",
        "            return 'test'\n",
        "        return 'train'\n",
        "\n",
        "    def data_padding(self, data):\n",
        "        \"\"\"Padding short segments of data with 0s\"\"\"\n",
        "        return np.pad(data, (0, self.segment_length - data.shape[0]), 'constant', constant_values=0)\n",
        "\n",
        "    def generate_data(self):\n",
        "        \"\"\"generates train test validation sets before calculating zscore \"\"\"\n",
        "        for wav_name in sorted(self.wav_files.keys()):\n",
        "            len = self.wav_files[wav_name]['len']\n",
        "            emotion = self.wav_files[wav_name]['emotion']\n",
        "            set_type = self.find_set(wav_name)  # train/test/validation\n",
        "            filename = self.wav_files[wav_name]['path']\n",
        "\n",
        "            part = self.read_wav_file(filename)\n",
        "\n",
        "            if set_type == 'train':\n",
        "                if len <= self.sample_length[emotion]:\n",
        "                    continue\n",
        "                samples = divmod(len, self.sample_length[emotion])[0] \n",
        "                start_times = [random.randint(i * self.sample_length[emotion], \n",
        "                                              (i+1)* self.sample_length[emotion]-self.segment_length) for i in range(samples)]\n",
        "            else:\n",
        "                segments = divmod(len, self.segment_length)[0] \n",
        "                start_times = [i * self.segment_length for i in range(segments)]\n",
        "            \n",
        "            end_times = [i + self.segment_length for i in start_times]\n",
        "\n",
        "            emotion = self.generate_label(emotion)\n",
        "            for begin, end in zip(start_times, end_times):\n",
        "                self.add_to_set(part[begin:end], emotion, set_type) \n",
        "\n",
        "            if set_type == 'validation':\n",
        "                self.valid_label_utterance[self.valid_utterance_num] = emotion\n",
        "                self.valid_utterance_num += 1\n",
        "            if set_type == 'test':\n",
        "                self.test_label_utterance[self.test_utterance_num] = emotion\n",
        "                self.test_utterance_num += 1\n",
        "\n",
        "    def calculate_zscore(self):\n",
        "        \"\"\"calculates zscore from train data \"\"\"\n",
        "        self.mean = np.mean(self.train_data.reshape(self.train_num * self.segment_length),\n",
        "                             axis=0)\n",
        "        self.std = np.std(self.train_data.reshape(self.train_num * self.segment_length),\n",
        "                           axis=0)\n",
        "\n",
        "    def standardize_data(self):\n",
        "        \"\"\"Standardize train test validation sets after the calculation of zscore\"\"\"\n",
        "        for i in range(self.train_num):\n",
        "            self.train_data[i, :] = (self.train_data[i, :] - self.mean) / (self.std + self.eps)\n",
        "\n",
        "        for i in range(self.test_segment_num):\n",
        "            self.test_data[i, :] = (self.test_data[i, :] - self.mean) / (self.std + self.eps)\n",
        "\n",
        "        for i in range(self.valid_segment_num):\n",
        "            self.valid_data[i, :] = (self.valid_data[i, :] - self.mean) / (self.std + self.eps)\n",
        "\n",
        "    def class_indices(self):\n",
        "        \"\"\"\"Index of each emotion class instance in the training data\"\"\"\n",
        "        hap_index = np.arange(self.train_emt['hap'])\n",
        "        neu_index = np.arange(self.train_emt['neu'])\n",
        "        sad_index = np.arange(self.train_emt['sad'])\n",
        "        ang_index = np.arange(self.train_emt['ang'])\n",
        "\n",
        "        h2 = 0\n",
        "        a0 = 0\n",
        "        n3 = 0\n",
        "        s1 = 0\n",
        "\n",
        "        for i in range(self.train_num):\n",
        "            if self.train_label[i] == 0:\n",
        "                ang_index[a0] = i\n",
        "                a0 = a0 + 1\n",
        "            elif self.train_label[i] == 1:\n",
        "                sad_index[s1] = i\n",
        "                s1 = s1 + 1\n",
        "            elif self.train_label[i] == 2:\n",
        "                hap_index[h2] = i\n",
        "                h2 = h2 + 1\n",
        "            elif self.train_label[i] == 3:\n",
        "                neu_index[n3] = i\n",
        "                n3 = n3 + 1\n",
        "\n",
        "        return hap_index, sad_index, neu_index, ang_index\n",
        "\n",
        "    def generate_training_batch(self, hap_index, sad_index, neu_index, ang_index):\n",
        "        \"\"\"Generating a training batch with self.frame_num segments from each emotion\"\"\"\n",
        "        np.random.seed(0)\n",
        "        np.random.shuffle(neu_index)\n",
        "        np.random.seed(0)\n",
        "        np.random.shuffle(hap_index)\n",
        "        np.random.seed(0)\n",
        "        np.random.shuffle(sad_index)\n",
        "        np.random.seed(0)\n",
        "        np.random.shuffle(ang_index)\n",
        "\n",
        "        self.train_num = 4 * self.num_per_emo \n",
        "\n",
        "        train_label = np.empty((self.train_num, 1), dtype=np.int8)\n",
        "        train_data = np.empty((self.train_num, self.segment_length), dtype=np.float32)\n",
        "        train_data[0:self.num_per_emo] = self.train_data[hap_index[0:self.num_per_emo]].copy()\n",
        "        train_label[0:self.num_per_emo] = self.train_label[hap_index[0:self.num_per_emo]].copy()\n",
        "        train_data[self.num_per_emo:2 * self.num_per_emo] = self.train_data[sad_index[0:self.num_per_emo]].copy()\n",
        "        train_label[self.num_per_emo:2 * self.num_per_emo] = self.train_label[sad_index[0:self.num_per_emo]].copy()\n",
        "        train_data[2 * self.num_per_emo:3 * self.num_per_emo] = self.train_data[ang_index[0:self.num_per_emo]].copy()\n",
        "        train_label[2 * self.num_per_emo:3 * self.num_per_emo] = self.train_label[ang_index[0:self.num_per_emo]].copy()\n",
        "        train_data[3 * self.num_per_emo:] = self.train_data[neu_index[0:self.num_per_emo]].copy()\n",
        "        train_label[3 * self.num_per_emo:] = self.train_label[neu_index[0:self.num_per_emo]].copy()\n",
        "       \n",
        "        arr = np.arange(self.train_num)\n",
        "        np.random.seed(0)\n",
        "        np.random.shuffle(arr)\n",
        "        self.train_data = train_data[arr[0:]]\n",
        "        self.train_label = train_label[arr[0:]]\n",
        "\n",
        "    def preprocess(self, output_file_name, valid_session, valid_gender,\n",
        "                   test_session, test_gender):\n",
        "        \"\"\"Process the audio files to generate train/test/validation data with extracted features\"\"\"\n",
        "        # self.read_IEMOCAP()\n",
        "        self.valid_session = valid_session\n",
        "        self.valid_gender = valid_gender\n",
        "        self.test_session = test_session\n",
        "        self.test_gender = test_gender\n",
        "        self.output_file_name = output_file_name\n",
        "\n",
        "        self.count_data()\n",
        "        self.initialize()\n",
        "        self.generate_data()\n",
        "\n",
        "        hap_index, sad_index, neu_index, ang_index = self.class_indices()\n",
        "        self.generate_training_batch(hap_index, sad_index, neu_index, ang_index)\n",
        "\n",
        "        self.calculate_zscore()\n",
        "        self.standardize_data()\n",
        "\n",
        "        f = open(self.output_file_name, 'wb')\n",
        "        pickle.dump((\n",
        "            self.train_data, self.train_label,\n",
        "            self.test_data, self.test_label_utterance, self.test_label_segment, self.test_segments_per_utterance,\n",
        "            self.valid_data, self.valid_label_utterance, self.valid_label_segment, self.valid_segments_per_utterance),\n",
        "            f)\n",
        "        f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfBBMbD8nFdG"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlQk7iRPpOV4"
      },
      "source": [
        "## SincNet: Convolution Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkqhg_6lTXYI"
      },
      "source": [
        "def sinc(band, t_right):\n",
        "\n",
        "    y_right = tf.math.sin(2 * math.pi * band * t_right) / (2 * math.pi * band * t_right)\n",
        "    y_left = tf.reverse(y_right, [0])\n",
        "    y = tf.concat([y_left, tf.ones(1), y_right], 0)\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6g5fmp4Qnw0"
      },
      "source": [
        "class SincConv1D(tf.keras.layers.Layer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.N_filt = kwargs.pop('N_filt')\n",
        "        self.Filt_dim = kwargs.pop('Filt_dim')\n",
        "        self.fs = kwargs.pop('fs')\n",
        "        self.hidden_size = kwargs.pop('hidden_size')\n",
        "        \n",
        "        super(SincConv1D, self).__init__(*args, **kwargs)\n",
        "        \n",
        "        # The filters are trainable parameters.\n",
        "    \n",
        "        self.filt_b1 = tf.Variable(\n",
        "            initializers.GlorotNormal(seed=0)(shape=[self.N_filt]), \n",
        "            dtype=tf.float32,\n",
        "            trainable=True,\n",
        "            name='filt_b1')\n",
        "        self.filt_band = tf.Variable(\n",
        "            initializers.GlorotNormal(seed=0)(shape=[self.N_filt]), \n",
        "            dtype=tf.float32,\n",
        "            trainable=True,\n",
        "            name='filt_band')\n",
        "        # Mel Initialization of the filterbanks\n",
        "\n",
        "        low_freq_mel = 80\n",
        "        high_freq_mel = (2595 * np.log10(1 + (self.fs / 2) / 700))  # Convert Hz to Mel\n",
        "        mel_points = np.linspace(low_freq_mel, high_freq_mel, self.N_filt)  # Equally spaced in Mel scale\n",
        "        f_cos = (700 * (10**(mel_points / 2595) - 1)) # Convert Mel to Hz\n",
        "        b1 = np.roll(f_cos, 1)\n",
        "        b2 = np.roll(f_cos, -1)\n",
        "        b1[0] = 30\n",
        "        b2[-1] = (self.fs / 2) - 100\n",
        "        self.freq_scale = self.fs * 1.0\n",
        "        self.filt_b1.assign(tf.convert_to_tensor(b1/self.freq_scale, dtype=tf.float32))\n",
        "        self.filt_band.assign(tf.convert_to_tensor((b2-b1)/self.freq_scale, dtype=tf.float32))\n",
        "    \n",
        "    def call(self, x, **kwargs):\n",
        "        # Get beginning and end frequencies of the filters.\n",
        "        min_freq = 50.0\n",
        "        min_band = 50.0\n",
        "        filt_beg_freq = tf.math.abs(self.filt_b1) + min_freq / self.freq_scale\n",
        "        filt_end_freq = filt_beg_freq + (tf.math.abs(self.filt_band) + min_band / self.freq_scale)\n",
        "\n",
        "        # Filter window (hamming).\n",
        "        n = np.linspace(0, self.Filt_dim, self.Filt_dim)\n",
        "        window = 0.54 - 0.46 * tf.math.cos(2 * math.pi * n / self.Filt_dim)\n",
        "        window = tf.cast(tf.convert_to_tensor(window, dtype=tf.float64), tf.float32)\n",
        "\n",
        "        # TODO what is this?\n",
        "        t_right_linspace = np.linspace(1, (self.Filt_dim - 1) / 2, int((self.Filt_dim -1) / 2))\n",
        "        t_right = tf.cast(tf.convert_to_tensor(t_right_linspace / self.fs, dtype=tf.float64), tf.float32)\n",
        "\n",
        "        # Compute the filters.\n",
        "        output_list = []\n",
        "\n",
        "        for i in range(self.N_filt):\n",
        "            low_pass1 = 2 * filt_beg_freq[i] * sinc(filt_beg_freq[i] * self.freq_scale, t_right)\n",
        "            low_pass2 = 2 * filt_end_freq[i] * sinc(filt_end_freq[i] * self.freq_scale, t_right)\n",
        "            band_pass= (low_pass2 - low_pass1)\n",
        "            # print(band_pass.shape)\n",
        "            band_pass = band_pass / tf.reduce_max(band_pass)\n",
        "            output_list.append(band_pass * window)\n",
        "        \n",
        "        filters = tf.stack(output_list)\n",
        "\n",
        "        # Reshape the filters. must have 3 dims\n",
        "        filters = tf.reshape(filters, (self.N_filt, 1, self.Filt_dim))\n",
        "\n",
        "        # Do the convolution.\n",
        "        out = tf.nn.conv1d(\n",
        "            input=x, \n",
        "            filters=filters,\n",
        "            stride=1,\n",
        "            padding='SAME',\n",
        "        )\n",
        "        return out\n",
        "        \n",
        "    def get_config(self):\n",
        "        config = ({\n",
        "            'N_filt': self.N_filt,\n",
        "            'Filt_dim': self.Filt_dim,\n",
        "            'fs': self.fs,\n",
        "            'hidden_size': self.hidden_size,\n",
        "        })\n",
        "        base_config = super(SincConv1D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCy1jU_gp4ix"
      },
      "source": [
        "## Self Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KifZ9osZXFvP"
      },
      "source": [
        "class CustomAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.hidden_size = kwargs.pop('hidden_size')\n",
        "        super(CustomAttention, self).__init__(*args, **kwargs)\n",
        "        self.W_omega = tf.Variable(\n",
        "            initializers.GlorotNormal(seed=0)(shape=[self.hidden_size, 1]), \n",
        "            dtype=tf.float32,\n",
        "            trainable=True,\n",
        "            name=\"W_omega\")\n",
        "        self.b_omega = tf.Variable(\n",
        "            initializers.GlorotNormal(seed=0)(shape=[1]), \n",
        "            dtype=tf.float32,\n",
        "            trainable=True,\n",
        "            name=\"b_omega\")\n",
        "        self.u_omega = tf.Variable(\n",
        "            initializers.GlorotNormal(seed=0)(shape=[1]), \n",
        "            dtype=tf.float32,\n",
        "            trainable=True,\n",
        "            name=\"u_omega\")\n",
        "    \n",
        "    def call(self, inputs, **kwargs):\n",
        "        v = tf.sigmoid(tf.tensordot(inputs, self.W_omega, axes=1) + self.b_omega)\n",
        "        vu = tf.tensordot(v, self.u_omega, axes=1)\n",
        "        alphas = layers.Softmax()(vu)\n",
        "        return tf.reduce_sum(inputs * tf.expand_dims(alphas, -1), 1)\n",
        "        \n",
        "    def get_config(self):\n",
        "        config = ({\n",
        "            'hidden_size': self.hidden_size \n",
        "        })\n",
        "        base_config = super(CustomAttention, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBPU1VhxqFSU"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfvVm2MF68XT"
      },
      "source": [
        "default_params = {\n",
        "'FILTER_CONV1' : 128,\n",
        "'KERNEL_CONV1' : (3, 3),\n",
        "'STRIDE_CONV1' : (1, 1),\n",
        "'BIAS_INIT' : 'ones',\n",
        "'KERNEL_INIT' : 'glorot_normal',\n",
        "'PADDING_CONV1' : 'SAME',\n",
        "'BN_MOMENTUM' : 0.9,\n",
        "'LEAKY_ALPHA' : 0.01,\n",
        "'SIZE_POOL_CONV1' : (2, 4),\n",
        "'PADDING_POOL_CONV1' : 'VALID',\n",
        "'NUM_DIL_LAYERS' : 3,\n",
        "'FILTER_CONV_UFLB' : 128,\n",
        "'KERNEL_CONV_UFLB' :  (3, 3),\n",
        "'STRIDE_CONV_UFLB' : (1, 1),\n",
        "'DIL_RATE_CONV_UFLB' : (2, 2),\n",
        "'PADDING_CONV_UFLB' : 'SAME',\n",
        "'BILSTM_UNITS_SPEC' : 256,\n",
        "'UNITS_FCN' : [512, 256, 128, 64],\n",
        "'LR' : 0.00001,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6suyAFFJ2wCa"
      },
      "source": [
        "input_shape = (200, 40, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDNi91ap1oKF"
      },
      "source": [
        "def build_model(hparams=default_params):\n",
        "    \n",
        "    model_input_spec = Input(shape=input_shape, name='spec_features')\n",
        "\n",
        "    x = layers.Conv2D(filters=hparams['FILTER_CONV1'], kernel_size=hparams['KERNEL_CONV1'], \n",
        "                      strides=hparams['STRIDE_CONV1'], bias_initializer=hparams['BIAS_INIT'], \n",
        "                      kernel_initializer=hparams['KERNEL_INIT'],\n",
        "                      padding=hparams['PADDING_CONV1'], name='CONV1')(model_input_spec)\n",
        "\n",
        "    x = layers.LeakyReLU(alpha=hparams['LEAKY_ALPHA'],\n",
        "                         name='LEAKY_CONV1')(x)\n",
        "    \n",
        "    x = layers.MaxPooling2D(pool_size=hparams['SIZE_POOL_CONV1'], \n",
        "                            strides=hparams['SIZE_POOL_CONV1'], \n",
        "                            padding=hparams['PADDING_POOL_CONV1'], \n",
        "                            name='POOL_CONV1')(x)\n",
        "\n",
        "    conv_layer_output = x\n",
        "\n",
        "    for i in range(hparams['NUM_DIL_LAYERS']):\n",
        "        x = layers.Conv2D(filters=hparams['FILTER_CONV_UFLB'], \n",
        "                          kernel_size=hparams['KERNEL_CONV_UFLB'], \n",
        "                          strides=hparams['STRIDE_CONV_UFLB'],\n",
        "                          bias_initializer=hparams['BIAS_INIT'],\n",
        "                          kernel_initializer=hparams['KERNEL_INIT'],\n",
        "                          dilation_rate=hparams['DIL_RATE_CONV_UFLB'], \n",
        "                          padding=hparams['PADDING_CONV_UFLB'], \n",
        "                          name='CONV_UFLB_'+str(i+1))(x)\n",
        "        x = layers.BatchNormalization(momentum=hparams['BN_MOMENTUM'], \n",
        "                                      name='BN_CONV_UFLB_'+str(i+1))(x)\n",
        "        x = layers.LeakyReLU(alpha=hparams['LEAKY_ALPHA'],\n",
        "                             name='LEAKY_CONV_UFLB_'+str(i+1))(x)\n",
        "\n",
        "    skip_layer_output = layers.Conv2D(filters=hparams['FILTER_CONV_UFLB'], \n",
        "                                      kernel_size=hparams['KERNEL_CONV_UFLB'], \n",
        "                                      strides=hparams['STRIDE_CONV_UFLB'],\n",
        "                                      bias_initializer=hparams['BIAS_INIT'],\n",
        "                                      kernel_initializer=hparams['KERNEL_INIT'],\n",
        "                                      dilation_rate=hparams['DIL_RATE_CONV_UFLB'], \n",
        "                                      padding=hparams['PADDING_CONV_UFLB'], \n",
        "                                      name='CONV_ALT')(conv_layer_output)\n",
        "\n",
        "    skip_layer_output = layers.BatchNormalization(momentum=hparams['BN_MOMENTUM'], \n",
        "                                                  name='BN_CONV_ALT')(skip_layer_output)\n",
        "    \n",
        "    x = layers.Add(name='skip_connection')([x, skip_layer_output])\n",
        "    \n",
        "    time_step = x.shape[1]\n",
        "    linear_units = x.shape[2]*x.shape[3]\n",
        "    x = tf.reshape(x,[-1,time_step,linear_units])\n",
        "\n",
        "\n",
        "    x = layers.LeakyReLU(alpha=hparams['LEAKY_ALPHA'],\n",
        "                             name='LEAKY_LINEAR')(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(units=hparams['BILSTM_UNITS_SPEC'],\n",
        "                                         bias_initializer=hparams['BIAS_INIT'],\n",
        "                                         kernel_initializer=hparams['KERNEL_INIT'], \n",
        "                                         return_sequences=True))(x)\n",
        "    x = CustomAttention(hidden_size=x.shape[2])(x)\n",
        "\n",
        "    for i, n in enumerate(hparams['UNITS_FCN']):\n",
        "        x = layers.Dense(units=n, activation=\"linear\", \n",
        "                         name='fcn_dense'+str(i+1))(x)\n",
        "        x = layers.LeakyReLU(alpha=hparams['LEAKY_ALPHA'], \n",
        "                             name='fcn_leaky'+str(i+1))(x)\n",
        "    \n",
        "    x = layers.Dense(units=4, activation=\"softmax\", name='Softmax')(x)\n",
        "\n",
        "    model = Model(inputs=model_input_spec, outputs=x, name=\"model_adrnn\") \n",
        "\n",
        "    model.compile(\n",
        "        loss=losses.CategoricalCrossentropy(from_logits=False),\n",
        "        optimizer=optimizers.Adam(\n",
        "            learning_rate=hparams['LR']\n",
        "        ),\n",
        "        metrics=['categorical_accuracy'],\n",
        "    )\n",
        "    print(model.summary())\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpqtJ67kXdtY"
      },
      "source": [
        "input_shape = (8000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOyYWQ5gyZIt"
      },
      "source": [
        "default_params = {\n",
        "'FILTER_CONV' : [80, 60, 60],\n",
        "'KERNEL_CONV' : [251, 5, 5],\n",
        "'SAMPLING_RATE': 16000,\n",
        "'SIZE_POOL': [3, 3, 3],\n",
        "'PADDING_POOL': 'VALID',\n",
        "'BIAS_INIT' : 'ones',\n",
        "'KERNEL_INIT' : 'glorot_normal',\n",
        "'PADDING_CONV' : 'SAME',\n",
        "'BN_MOMENTUM' : 0.05,\n",
        "'LEAKY_ALPHA' : 0.2,\n",
        "'BILSTM_UNITS' : 256,\n",
        "'UNITS_FCN' : [512, 128, 64, 4],\n",
        "'LR' : 0.00001,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQIDSvoYXRjQ"
      },
      "source": [
        "def build_model(hparams=default_params):\n",
        "    \n",
        "    model_input = Input(shape=input_shape, name='raw_waveform_data')\n",
        "\n",
        "    x = tf.expand_dims(model_input, -1)\n",
        "\n",
        "    x = SincConv1D(N_filt=hparams['FILTER_CONV'][0], \n",
        "                   Filt_dim=hparams['KERNEL_CONV'][0], \n",
        "                   fs=hparams['SAMPLING_RATE'],\n",
        "                   hidden_size=x.shape[1])(x)\n",
        "\n",
        "    x = layers.MaxPooling1D(pool_size=hparams['SIZE_POOL'][0], \n",
        "                            padding=hparams['PADDING_POOL'], \n",
        "                            name='pool_conv1')(x)\n",
        "\n",
        "    x = layers.BatchNormalization(momentum=hparams['BN_MOMENTUM'], \n",
        "                                  name='bn_conv1')(x)\n",
        "\n",
        "    x = layers.LeakyReLU(alpha=hparams['LEAKY_ALPHA'],\n",
        "                         name='leaky_conv1')(x)\n",
        "\n",
        "    for i in range(1, len(hparams['FILTER_CONV'])):\n",
        "\n",
        "        x = layers.Conv1D(filters=hparams['FILTER_CONV'][i], \n",
        "                          kernel_size=hparams['KERNEL_CONV'][i], \n",
        "                          bias_initializer=hparams['BIAS_INIT'],\n",
        "                          kernel_initializer=hparams['KERNEL_INIT'],\n",
        "                          padding=hparams['PADDING_CONV'], \n",
        "                          name='conv' + str(i+1))(x)\n",
        "\n",
        "        x = layers.MaxPooling1D(pool_size=hparams['SIZE_POOL'][i], \n",
        "                                padding=hparams['PADDING_POOL'], \n",
        "                                name='pool_conv' + str(i+1))(x)\n",
        "        \n",
        "        x = layers.BatchNormalization(momentum=hparams['BN_MOMENTUM'], \n",
        "                                        name='bn_conv' + str(i+1))(x)\n",
        "\n",
        "        x = layers.LeakyReLU(alpha=hparams['LEAKY_ALPHA'],\n",
        "                            name='leaky_conv1' + str(i+1))(x)\n",
        "    \n",
        "    x = layers.Bidirectional(layers.LSTM(units=hparams['BILSTM_UNITS'],\n",
        "                                         bias_initializer=hparams['BIAS_INIT'],\n",
        "                                         kernel_initializer=hparams['KERNEL_INIT'], \n",
        "                                         return_sequences=True))(x)\n",
        "    x = CustomAttention(hidden_size=x.shape[2])(x)\n",
        "\n",
        "    for i, n in enumerate(hparams['UNITS_FCN']):\n",
        "        x = layers.Dense(units=n, activation=\"linear\", \n",
        "                         name='fcn_dense'+str(i+1))(x)\n",
        "        x = layers.LeakyReLU(alpha=hparams['LEAKY_ALPHA'], \n",
        "                             name='fcn_leaky'+str(i+1))(x)\n",
        "\n",
        "    model = Model(inputs=model_input, outputs=x, name=\"model_sincnet\") \n",
        "\n",
        "    model.compile(\n",
        "        loss=losses.CategoricalCrossentropy(from_logits=True),\n",
        "        optimizer=optimizers.Adam(\n",
        "            learning_rate=hparams['LR']\n",
        "        ),\n",
        "        metrics=['categorical_accuracy'],\n",
        "    )\n",
        "    print(model.summary())\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gQo-oek-aLj"
      },
      "source": [
        "# Retrieve Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhQ86j49UXaX"
      },
      "source": [
        "def retrieve_preprocessed_data(session):\n",
        "    idx = session - 1\n",
        "    speaker = speaker_list[idx]\n",
        "    next_speaker = speaker_list[(idx+1)%10]\n",
        "    file_code = 'Valid_' + speaker + 'Test_' + next_speaker\n",
        "    data_file_name = dataset_dir + '/data' + file_code + '.pkl'\n",
        "    print(data_file_name)\n",
        "\n",
        "    f = open(data_file_name, 'rb')\n",
        "    output = pickle.load(f)\n",
        "    train_features, train_labels = output[0], output[1]  \n",
        "    test_features, test_labels, test_segments_per_utterance = output[2], output[3], output[5]\n",
        "    valid_features, valid_labels, valid_segments_per_utterance = output[6], output[7], output[9]  \n",
        "    f.close()\n",
        "\n",
        "    train_features = tf.convert_to_tensor(train_features, dtype=tf.float32)\n",
        "    valid_features = tf.convert_to_tensor(valid_features, dtype=tf.float32)\n",
        "    test_features = tf.convert_to_tensor(test_features, dtype=tf.float32)\n",
        "    \n",
        "    train_labels = tf.one_hot(train_labels, 4, dtype=tf.float32)\n",
        "    valid_labels = tf.one_hot(valid_labels, 4, dtype=tf.float32)\n",
        "    test_labels = tf.one_hot(test_labels, 4, dtype=tf.float32)\n",
        "\n",
        "    train_labels = tf.reshape(train_labels, [train_labels.shape[0], 4])\n",
        "    valid_labels = tf.reshape(valid_labels, [valid_labels.shape[0], 4])\n",
        "    test_labels = tf.reshape(test_labels, [test_labels.shape[0], 4])\n",
        "\n",
        "    return train_features, train_labels, valid_features, valid_labels, valid_segments_per_utterance, \\\n",
        "    test_features, test_labels, test_segments_per_utterance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyZ_n8PQIDug"
      },
      "source": [
        "# Train and Evaulate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2tmOznUV2ye"
      },
      "source": [
        "def train_and_evaluate(model, num_epochs=1200):\n",
        "    i=0\n",
        "    best_valid_accuracy = 0\n",
        "    best_epoch = 0\n",
        "\n",
        "    while i< num_epochs:\n",
        "        start = (i*60)%train_features.shape[0]\n",
        "        end = min(start+60, train_features.shape[0])\n",
        "        train_batch = train_features[start:end, :]\n",
        "        train_batch_label = train_labels[start:end,:]\n",
        "\n",
        "        loss = model.train_on_batch(train_batch, train_batch_label, return_dict=True)\n",
        "\n",
        "        if((i+1)%5==0):\n",
        "            valid_acc_uw, valid_conf = evaluate(model, valid_features, \n",
        "                                                valid_segments_per_utterance, \n",
        "                                                valid_labels)\n",
        "            \n",
        "            if valid_acc_uw > best_valid_accuracy:\n",
        "                best_epoch = i+1\n",
        "                best_valid_accuracy = valid_acc_uw\n",
        "                test_accuracy, test_conf = evaluate(model, test_features, \n",
        "                                                    test_segments_per_utterance, \n",
        "                                                    test_labels)\n",
        "                print('*'*30)\n",
        "                print(\"Epoch: %05d\" %(i+1))\n",
        "                print(\"Training accuracy: \" + str(loss['categorical_accuracy']))\n",
        "                print(\"Valid_UA: \" + str(valid_acc_uw)) \n",
        "                print(\"Test UA: \" + str(test_accuracy))    \n",
        "\n",
        "        i += 1\n",
        "\n",
        "    print('*'*30)\n",
        "    print(\"Best Epoch: %05d\" %(best_epoch))\n",
        "    print(\"Best Valid Accuracy: \" + str(best_valid_accuracy))\n",
        "    print(\"Test_UA: \" + str(test_accuracy))    \n",
        "    print('Test Confusion Matrix:[\"ang\",\"sad\",\"hap\",\"neu\"]')\n",
        "    print(test_conf)\n",
        "\n",
        "    return "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyTxWSWaMo2v"
      },
      "source": [
        "def evaluate(model, features, segments_per_utterance, labels, pooling='avg'):\n",
        "    y_pred = np.empty((len(segments_per_utterance),4),dtype=np.float32)\n",
        "    y_pred_segments = model.predict(features)\n",
        "    index=0\n",
        "    for j in range(len(segments_per_utterance)):\n",
        "        if pooling == 'max':\n",
        "            y_pred[j,:] = np.max(y_pred_segments[index:index+segments_per_utterance[j][0],:],0) \n",
        "        else:\n",
        "            y_pred[j,:] = np.sum(y_pred_segments[index:index+segments_per_utterance[j][0],:],0)\n",
        "        index+=(segments_per_utterance[j][0])\n",
        "\n",
        "    acc_uw = recall(np.argmax(labels,1),np.argmax(y_pred,1),average='macro')\n",
        "    conf = confusion(np.argmax(labels, 1),np.argmax(y_pred,1))\n",
        "    return acc_uw, conf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4KAQgnHs3CA"
      },
      "source": [
        "# Sincnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh9ha8hwLVp2",
        "outputId": "9e06b1ea-e537-4235-fb2e-c07d60676bda"
      },
      "source": [
        "model = build_model()\n",
        "train_and_evaluate(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_sincnet\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "raw_waveform_data (InputLaye [(None, 4000)]            0         \n",
            "_________________________________________________________________\n",
            "tf.expand_dims_7 (TFOpLambda (None, 4000, 1)           0         \n",
            "_________________________________________________________________\n",
            "sinc_conv1d_7 (SincConv1D)   (None, 4000, 251)         160       \n",
            "_________________________________________________________________\n",
            "pool_conv1 (MaxPooling1D)    (None, 1333, 251)         0         \n",
            "_________________________________________________________________\n",
            "bn_conv1 (BatchNormalization (None, 1333, 251)         1004      \n",
            "_________________________________________________________________\n",
            "leaky_conv1 (LeakyReLU)      (None, 1333, 251)         0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv1D)               (None, 1333, 60)          75360     \n",
            "_________________________________________________________________\n",
            "pool_conv2 (MaxPooling1D)    (None, 444, 60)           0         \n",
            "_________________________________________________________________\n",
            "bn_conv2 (BatchNormalization (None, 444, 60)           240       \n",
            "_________________________________________________________________\n",
            "leaky_conv12 (LeakyReLU)     (None, 444, 60)           0         \n",
            "_________________________________________________________________\n",
            "conv3 (Conv1D)               (None, 444, 60)           18060     \n",
            "_________________________________________________________________\n",
            "pool_conv3 (MaxPooling1D)    (None, 148, 60)           0         \n",
            "_________________________________________________________________\n",
            "bn_conv3 (BatchNormalization (None, 148, 60)           240       \n",
            "_________________________________________________________________\n",
            "leaky_conv13 (LeakyReLU)     (None, 148, 60)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 148, 512)          649216    \n",
            "_________________________________________________________________\n",
            "custom_attention_7 (CustomAt (None, 512)               514       \n",
            "_________________________________________________________________\n",
            "fcn_dense1 (Dense)           (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "fcn_leaky1 (LeakyReLU)       (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "fcn_dense2 (Dense)           (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "fcn_leaky2 (LeakyReLU)       (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "fcn_dense3 (Dense)           (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "fcn_leaky3 (LeakyReLU)       (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "fcn_dense4 (Dense)           (None, 4)                 260       \n",
            "_________________________________________________________________\n",
            "fcn_leaky4 (LeakyReLU)       (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 1,081,630\n",
            "Trainable params: 1,080,888\n",
            "Non-trainable params: 742\n",
            "_________________________________________________________________\n",
            "None\n",
            "******************************\n",
            "Epoch: 00005\n",
            "Training accuracy: 0.21666666865348816\n",
            "Valid_UA: 0.25\n",
            "Test UA: 0.25\n",
            "******************************\n",
            "Epoch: 00020\n",
            "Training accuracy: 0.30000001192092896\n",
            "Valid_UA: 0.40128968253968256\n",
            "Test UA: 0.23961538461538462\n",
            "******************************\n",
            "Epoch: 00045\n",
            "Training accuracy: 0.4166666567325592\n",
            "Valid_UA: 0.41666666666666663\n",
            "Test UA: 0.33365384615384613\n",
            "******************************\n",
            "Epoch: 00085\n",
            "Training accuracy: 0.46666666865348816\n",
            "Valid_UA: 0.451986844966297\n",
            "Test UA: 0.3708974358974359\n",
            "******************************\n",
            "Epoch: 00095\n",
            "Training accuracy: 0.3499999940395355\n",
            "Valid_UA: 0.4823399108501848\n",
            "Test UA: 0.4228205128205128\n",
            "******************************\n",
            "Epoch: 00150\n",
            "Training accuracy: 0.3333333432674408\n",
            "Valid_UA: 0.49716650358773645\n",
            "Test UA: 0.39121794871794874\n",
            "******************************\n",
            "Epoch: 00190\n",
            "Training accuracy: 0.3499999940395355\n",
            "Valid_UA: 0.5251821048053925\n",
            "Test UA: 0.39038461538461533\n",
            "******************************\n",
            "Epoch: 00290\n",
            "Training accuracy: 0.38333332538604736\n",
            "Valid_UA: 0.5575980021571059\n",
            "Test UA: 0.3421003016591252\n",
            "******************************\n",
            "Epoch: 00485\n",
            "Training accuracy: 0.38333332538604736\n",
            "Valid_UA: 0.5757605130110346\n",
            "Test UA: 0.4411689291101056\n",
            "******************************\n",
            "Epoch: 01045\n",
            "Training accuracy: 0.38333332538604736\n",
            "Valid_UA: 0.57996699541651\n",
            "Test UA: 0.4154920814479638\n",
            "******************************\n",
            "Epoch: 01090\n",
            "Training accuracy: 0.4333333373069763\n",
            "Valid_UA: 0.6057979509654416\n",
            "Test UA: 0.4047567873303167\n",
            "******************************\n",
            "Best Epoch: 01090\n",
            "Best Valid Accuracy: 0.6057979509654416\n",
            "Test_UA: 0.4047567873303167\n",
            "Test Confusion Matrix:[\"ang\",\"sad\",\"hap\",\"neu\"]\n",
            "[[ 5  1  2  5]\n",
            " [ 8 33  5 14]\n",
            " [15  1 14 20]\n",
            " [18 43 20 55]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7Z8hXv9Qirr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}